# main.py
import streamlit as st
import duckdb
import pandas as pd
import pyodbc
import oracledb
from datetime import datetime, date
import time


# Initialize persistent DuckDB connection
def get_duckdb_connection():
    return duckdb.connect(database='data_warehouse.duckdb')


# Initialize database schema
with get_duckdb_connection() as conn:
    conn.execute("""
        CREATE SCHEMA IF NOT EXISTS metadata;
        CREATE TABLE IF NOT EXISTS metadata.query_config (
            query_id INTEGER PRIMARY KEY,
            sql_text VARCHAR,
            instance_name VARCHAR,
            target_table VARCHAR,
            db_type VARCHAR,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );

        CREATE TABLE IF NOT EXISTS metadata.runs (
            run_id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
            query_id INTEGER,
            status VARCHAR,
            rows_affected INTEGER,
            execution_time_ms INTEGER,
            run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY(query_id) REFERENCES metadata.query_config(query_id)
        );
    """)

# Database configuration (Update with your credentials)
DATABASE_CONFIG = {
    'sybase_instance1': {
        'type': 'sybase',
        'driver': 'FreeTDS',
        'server': 'your_sybase_server1',
        'database': 'db1',
        'uid': 'username1',
        'pwd': 'password1',
        'port': '1433'
    },
    'sybase_instance2': {
        'type': 'sybase',
        'driver': 'FreeTDS',
        'server': 'your_sybase_server2',
        'database': 'db2',
        'uid': 'username2',
        'pwd': 'password2',
        'port': '1433'
    },
    'oracle_instance1': {
        'type': 'oracle',
        'user': 'system',
        'password': 'oracle_pass',
        'dsn': 'localhost:1521/XE',
        'service_name': 'XE'
    }
}


def execute_query(sql, instance_name, db_type, params):
    """Execute SQL on target database and return DataFrame"""
    config = DATABASE_CONFIG[instance_name]

    try:
        if db_type == 'sybase':
            conn_str = (
                f"DRIVER={{{config['driver']}}};"
                f"SERVER={config['server']};"
                f"DATABASE={config['database']};"
                f"UID={config['uid']};"
                f"PWD={config['pwd']};"
                f"PORT={config['port']};"
            )
            with pyodbc.connect(conn_str) as conn:
                return pd.read_sql_query(sql, conn, params=params)

        elif db_type == 'oracle':
            dsn = oracledb.makedsn(
                config['server'].split(':')[0],
                config['server'].split(':')[1],
                service_name=config['service_name']
            )
            with oracledb.connect(
                    user=config['user'],
                    password=config['password'],
                    dsn=dsn
            ) as conn:
                return pd.read_sql_query(sql, conn, params=params)

    except Exception as e:
        raise RuntimeError(f"Database connection failed: {str(e)}")


# Streamlit UI Configuration
st.set_page_config(
    page_title="Enterprise Data Pipeline",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Main App
def main():
    st.title("ðŸ“Š Enterprise Data Pipeline & Analytics")

    # Section 1: Query Management
    with st.sidebar.expander("ðŸ”§ Query Configuration", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Add/Update Query")
            query_id = st.number_input("Query ID", min_value=1, value=1)
            sql_text = st.text_area("SQL Query (use :start_date and :end_date)")
            instance_name = st.selectbox("Database Instance", list(DATABASE_CONFIG.keys()))
            target_table = st.text_input("Target Table Name")
            db_type = st.selectbox("Database Type", ['sybase', 'oracle'])

            if st.button("ðŸ’¾ Save Query"):
                with get_duckdb_connection() as conn:
                    conn.execute("""
                        INSERT OR REPLACE INTO metadata.query_config 
                        (query_id, sql_text, instance_name, target_table, db_type)
                        VALUES (?, ?, ?, ?, ?)
                    """, [query_id, sql_text, instance_name, target_table, db_type])
                    st.success("Query configuration saved!")

        with col2:
            st.subheader("Existing Queries")
            config_df = get_duckdb_connection().execute("""
                SELECT query_id, instance_name, target_table, db_type 
                FROM metadata.query_config
                ORDER BY query_id
            """).fetchdf()
            st.dataframe(config_df, use_container_width=True)

    # Section 2: Execution Parameters
    with st.sidebar.expander("â± Execution Parameters", expanded=True):
        start_date = st.date_input("Start Date", value=date(2023, 1, 1))
        end_date = st.date_input("End Date", value=date.today())
        run_all = st.button("ðŸš€ Execute All Queries", type="primary")

    # Main Content Area
    if run_all:
        conn = get_duckdb_connection()
        queries = conn.execute("SELECT * FROM metadata.query_config").fetchdf()

        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, (_, row) in enumerate(queries.iterrows()):
            try:
                start_time = time.time()
                status_text.markdown(f"**Processing:** {row['target_table']}...")

                # Format SQL with parameters
                params = {'start_date': start_date, 'end_date': end_date}
                df = execute_query(
                    sql=row['sql_text'],
                    instance_name=row['instance_name'],
                    db_type=row['db_type'],
                    params=params
                )

                # Persist data with versioning
                conn.execute(f"""
                    CREATE OR REPLACE TABLE {row['target_table']} AS 
                    SELECT *, 
                           CURRENT_TIMESTAMP AS load_timestamp,
                           '{start_date}' AS period_start,
                           '{end_date}' AS period_end
                    FROM df
                """)

                # Log execution
                execution_time = int((time.time() - start_time) * 1000)
                conn.execute("""
                    INSERT INTO metadata.runs 
                    (query_id, status, rows_affected, execution_time_ms)
                    VALUES (?, ?, ?, ?)
                """, [row['query_id'], 'success', len(df), execution_time])

                st.success(f"""
                    âœ… {row['target_table']}
                    - Rows: {len(df):,}
                    - Time: {execution_time}ms
                """)

            except Exception as e:
                conn.execute("""
                    INSERT INTO metadata.runs 
                    (query_id, status, execution_time_ms)
                    VALUES (?, ?, ?)
                """, [row['query_id'], 'failed', 0])
                st.error(f"""
                    âŒ Failed {row['target_table']}
                    - Error: {str(e)}
                """)

            progress_bar.progress((i + 1) / len(queries))

        status_text.success("âœ… All queries processed!")

    # Section 3: Analytics Dashboard
    st.header("ðŸ“ˆ Analytics Dashboard")

    tab1, tab2, tab3, tab4 = st.tabs(["Data Explorer", "Performance", "Custom Analysis", "Export"])

    with tab1:
        tables = get_duckdb_connection().execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'main'
        """).fetchdf()

        selected_table = st.selectbox("Choose Table", tables['table_name'].tolist())
        if selected_table:
            df_preview = get_duckdb_connection().execute(f"""
                SELECT * 
                FROM {selected_table} 
                ORDER BY load_timestamp DESC 
                LIMIT 1000
            """).fetchdf()
            st.dataframe(df_preview, use_container_width=True)

            # Automatic visualization
            numeric_cols = df_preview.select_dtypes(include='number').columns.tolist()
            if numeric_cols:
                selected_metric = st.selectbox("Select Metric", numeric_cols)
                st.line_chart(df_preview, x='load_timestamp', y=selected_metric)

    with tab2:
        st.subheader("Performance Metrics")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Execution History**")
            run_history = get_duckdb_connection().execute("""
                SELECT 
                    r.run_timestamp,
                    q.target_table,
                    r.execution_time_ms,
                    r.rows_affected
                FROM metadata.runs r
                JOIN metadata.query_config q ON r.query_id = q.query_id
                ORDER BY r.run_timestamp DESC
                LIMIT 100
            """).fetchdf()
            st.dataframe(run_history, use_container_width=True)

        with col2:
            st.markdown("**Performance Summary**")
            performance_df = get_duckdb_connection().execute("""
                SELECT 
                    q.target_table,
                    AVG(r.execution_time_ms) AS avg_time,
                    MAX(r.execution_time_ms) AS max_time,
                    MIN(r.execution_time_ms) AS min_time,
                    COUNT(*) AS total_runs
                FROM metadata.runs r
                JOIN metadata.query_config q ON r.query_id = q.query_id
                GROUP BY q.target_table
            """).fetchdf()
            st.bar_chart(performance_df.set_index('target_table'))

    with tab3:
        st.subheader("SQL Analysis Console")
        custom_sql = st.text_area("Enter SQL Query (use 'main.' prefix for tables)", height=200)

        if st.button("â–¶ï¸ Execute"):
            try:
                result = get_duckdb_connection().execute(custom_sql).fetchdf()
                st.dataframe(result, use_container_width=True)

                # Basic visualization
                if not result.empty:
                    numeric_cols = result.select_dtypes(include='number').columns
                    if len(numeric_cols) > 0:
                        x_col = st.selectbox("X-Axis", result.columns)
                        y_col = st.selectbox("Y-Axis", numeric_cols)
                        st.line_chart(result, x=x_col, y=y_col)

            except Exception as e:
                st.error(f"Query Error: {str(e)}")

    with tab4:
        st.subheader("Data Export")
        export_table = st.selectbox("Select Table to Export", tables['table_name'].tolist())

        if export_table and st.button("ðŸ“¤ Export to CSV"):
            df_export = get_duckdb_connection().execute(f"""
                SELECT * FROM {export_table}
            """).fetchdf()

            st.download_button(
                label="Download CSV",
                data=df_export.to_csv(index=False).encode('utf-8'),
                file_name=f"{export_table}.csv",
                mime='text/csv'
            )


if __name__ == "__main__":
    main()